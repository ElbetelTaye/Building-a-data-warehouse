{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging for better tracking of progress\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert JSON to DataFrame\n",
    "def json_to_dataframe(json_path):\n",
    "    \"\"\"Converts a JSON file to a pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_json(json_path)\n",
    "        logging.info(f\"Successfully loaded data from {json_path}\")\n",
    "        return df\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error reading {json_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if there's an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the DataFrame\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"Cleans the DataFrame by handling missing values, duplicates, etc.\"\"\"\n",
    "    if df.empty:\n",
    "        logging.warning(\"DataFrame is empty. Skipping cleaning.\")\n",
    "        return df\n",
    "    \n",
    "    # Example cleaning steps (customize as needed):\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
    "    \n",
    "    # Convert date columns to datetime if present\n",
    "    for col in df.columns:\n",
    "        if 'date' in col.lower():\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    logging.info(\"Data cleaning completed.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned DataFrame as a CSV file\n",
    "def save_cleaned_data(df, output_path):\n",
    "    df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Cleaned data saved to {output_path}\")\n",
    "\n",
    "# Function to store DataFrame in a database\n",
    "def store_in_database(df, table_name, database_url):\n",
    "    engine = create_engine(database_url)\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "    logging.info(f\"Data stored in the '{table_name}' table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill for missing values\n",
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_21692\\2211415210.py:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill if any remain\n"
     ]
    }
   ],
   "source": [
    "# Main function to process all JSON files in a directory\n",
    "def process_all_json_files(input_folder, output_folder, database_url=None):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Loop through each JSON file in the input folder\n",
    "    for json_file in os.listdir(input_folder):\n",
    "        if json_file.endswith('.json'):\n",
    "            input_path = os.path.join(input_folder, json_file)\n",
    "            logging.info(f\"Processing file: {input_path}\")\n",
    "            \n",
    "            # Convert JSON to DataFrame\n",
    "            df = json_to_dataframe(input_path)\n",
    "            \n",
    "            # Clean the DataFrame\n",
    "            cleaned_df = clean_dataframe(df)\n",
    "            \n",
    "            # Define output file path\n",
    "            output_file = os.path.join(output_folder, f\"cleaned_{json_file.replace('.json', '.csv')}\")\n",
    "            \n",
    "            # Save the cleaned data\n",
    "            save_cleaned_data(cleaned_df, output_file)\n",
    "            logging.info(f\"Saved cleaned data to: {output_file}\")\n",
    "            \n",
    "            # Optionally, store the cleaned data in a database\n",
    "            if database_url:\n",
    "                table_name = os.path.splitext(json_file)[0]  # Use the file name as the table name\n",
    "                store_in_database(cleaned_df, table_name, database_url)\n",
    "\n",
    "# Example usage\n",
    "input_folder = 'C:/Users/elbet/OneDrive/Desktop/Ten/week-7/github/Building-a-data-warehouse/scrapped_json_files'  \n",
    "output_folder = 'C:/Users/elbet/OneDrive/Desktop/Ten/week-7/github/Building-a-data-warehouse/cleaned_files' \n",
    "database_url = 'postgresql://postgres:qwer1234@127.0.0.1:5432/warehouse' \n",
    "\n",
    "# Process all JSON files and optionally store in a database\n",
    "process_all_json_files(input_folder, output_folder, database_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
